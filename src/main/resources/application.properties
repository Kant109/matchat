spring.application.name=matchat
### Global configurations
# Base URL for Mistral AI endpoints
langchain4j.ollama.chat-model.base-url=http://localhost:11434/
# Activate or not the log during the request
langchain4j.ollama.chat-model.log-requests=true
# Delay before raising a timeout exception
langchain4j.ollama.timeout=60s    
# Activate or not the Mistral AI embedding model
langchain4j.ollama.embedding-model.enabled=false

### Chat model configurations
# Activate or not the Mistral AI chat model
langchain4j.ollama.chat-model.enabled=true              
# Chat model name used
langchain4j.ollama.chat-model.model-name=mistral
langchain4j.ollama.chat-model.timeout=120



